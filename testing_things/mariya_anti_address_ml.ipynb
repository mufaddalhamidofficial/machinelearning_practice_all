{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "eadc3d20",
      "metadata": {},
      "source": [
        "# Seq2Seq Model for Text Transformation\n",
        "\n",
        "This notebook demonstrates how to train a Seq2Seq model for text transformation using TensorFlow. The model can be used to transform input texts into desired output texts based on the training data provided.\n",
        "\n",
        "The notebook is organized into the following sections:\n",
        "1. Load Data from JSON\n",
        "2. Tokenize Sequences\n",
        "3. Create the Seq2Seq Model\n",
        "4. Compile and Train the Model\n",
        "5. Save the Model\n",
        "6. Generate Transformed Output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea6c8a0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2b1991ea",
      "metadata": {},
      "source": [
        "## 1. Load Data from JSON\n",
        "\n",
        "In this section, we load the input-output data from a JSON file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcefdcf0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data from JSON file\n",
        "with open('mariya_anti_data.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "input_texts = []\n",
        "output_texts = []\n",
        "for item in data:\n",
        "    input_text = item['input']\n",
        "    output_text = item['output']\n",
        "    input_texts.append(input_text)\n",
        "    output_texts.append(output_text)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "54695826",
      "metadata": {},
      "source": [
        "## 2. Tokenize Sequences\n",
        "\n",
        "In this section, we tokenize the input and output sequences and prepare them for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd9a5cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenize input and output sequences\n",
        "input_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "input_tokenizer.fit_on_texts(input_texts)\n",
        "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
        "max_input_length = max(len(seq) for seq in input_sequences)\n",
        "input_sequences = tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_input_length)\n",
        "\n",
        "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "output_tokenizer.fit_on_texts(output_texts)\n",
        "output_sequences = output_tokenizer.texts_to_sequences(output_texts)\n",
        "max_output_length = max(len(seq) for seq in output_sequences)\n",
        "output_sequences = tf.keras.preprocessing.sequence.pad_sequences(output_sequences, maxlen=max_output_length)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a4e78c05",
      "metadata": {},
      "source": [
        "## 3. Create the Seq2Seq Model\n",
        "\n",
        "In this section, we define and configure the Seq2Seq model architecture using TensorFlow's Keras API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b14415",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the Seq2Seq model\n",
        "embedding_dim = 128\n",
        "hidden_units = 256\n",
        "\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "encoder_embedding = tf.keras.layers.Embedding(len(input_tokenizer.word_index) + 1, embedding_dim)(encoder_inputs)\n",
        "encoder_lstm = tf.keras.layers.LSTM(hidden_units, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "decoder_embedding = tf.keras.layers.Embedding(len(output_tokenizer.word_index) + 1, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM(hidden_units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = tf.keras.layers.Dense(len(output_tokenizer.word_index) + 1, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs[:, :-1, :])  # Remove the last timestamp from the output\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e920c54c",
      "metadata": {},
      "source": [
        "## 4. Compile and Train the Model\n",
        "\n",
        "In this section, we compile and train the Seq2Seq model using the tokenized input and output sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a8b4a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile and train the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy')\n",
        "model.fit([input_sequences, output_sequences[:, :-1]], np.expand_dims(output_sequences[:, 1:], -1), batch_size=1, epochs=50)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e05c5766",
      "metadata": {},
      "source": [
        "## 5. Save the Model\n",
        "\n",
        "In this section, we save the trained Seq2Seq model for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8f9672b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save('seq2seq_model.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "635effcb",
      "metadata": {},
      "source": [
        "## 6. Generate Transformed Output\n",
        "\n",
        "In this section, we define a function to generate transformed output for new input texts using the trained Seq2Seq model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7975527",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate transformed output using the trained model\n",
        "def generate_transformed_output(input_text):\n",
        "    input_sequence = input_tokenizer.texts_to_sequences([input_text])\n",
        "    input_sequence = tf.keras.preprocessing.sequence.pad_sequences(input_sequence, maxlen=input_sequences.shape[1])\n",
        "    output_sequence = np.zeros((1, output_sequences.shape[1]))\n",
        "\n",
        "    for i in range(output_sequences.shape[1]):\n",
        "        predictions = model.predict([input_sequence, output_sequence]).argmax(axis=-1)\n",
        "        output_sequence[0, i] = predictions[0, i]\n",
        "\n",
        "    output_text = output_tokenizer.sequences_to_texts(output_sequence)[0]\n",
        "    return output_text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fb99f179",
      "metadata": {},
      "source": [
        "## Test the Model\n",
        "\n",
        "In this section, you can test the model with sample input texts and observe the transformed outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a37de4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the model with a sample input\n",
        "input_text = input(\"Enter text: \")\n",
        "transformed_output = generate_transformed_output(input_text)\n",
        "print(\"Input:\", input_text)\n",
        "print(\"Transformed Output:\", transformed_output)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
